{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "#from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#\n",
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 174s - loss: 2.0033\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"een understood\n",
      "hitherto, as intention-mo\"\n",
      "een understood\n",
      "hitherto, as intention-moral the some it is the most the sense and soul the such a thing that it is the soul the most the soul and the sumple and the some and the some is the soul the soul the some of the soul the soul the soul the soul the soul the soul and the sense and the soul the present the soul the soul and the some such a precessable and the sense and the soul the present and the sumple of the sense and the proble\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"een understood\n",
      "hitherto, as intention-mo\"\n",
      "een understood\n",
      "hitherto, as intention-morality in the premation of the serfing the devent, and the restinction and deverse believe the proble, sumplequation of the serse and be from the\n",
      "sumples been comes the weel to the sentant the some in the plable and it is the\n",
      "stranged remant, and about man have and no the belief it is everyther and belate the sanifity and the soul himself them the proble and strung to the be in the precessary he w\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"een understood\n",
      "hitherto, as intention-mo\"\n",
      "een understood\n",
      "hitherto, as intention-monarifferened of the home. that\n",
      "hil many--movints, when main the ;philonor strean reamity.\"\n",
      "\n",
      "\n",
      "that\n",
      "we it--and interare distrunts of the morsle and freatheroy renol crusity whelestable and and distrivingiso, the\n",
      "slef\n",
      "condenius, constort ffeeing with itself a strabley, so a? abwasivoly all anceived, dewi we dow from--hon\n",
      "synt,\n",
      "we mavies from  \", an the nor perhas drenghath beprestherous the spreastar\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"een understood\n",
      "hitherto, as intention-mo\"\n",
      "een understood\n",
      "hitherto, as intention-molity a tila-poossable therehalud, willyt\n",
      "d plut, bordest., even hat that it\n",
      "-as hi sar plefirature in the astimal putt ftom in conceds which that\n",
      "the poul from the can vely horstops firm and ressients even moobles: that that they a\n",
      "reknow, the ats\n",
      "had ahid contaits of lee1.\n",
      "!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "21hi\n",
      "\n",
      "=e, its bibloon of\n",
      "civactle, by . \"purse, in etrotmout one preoinm to canebly modt vastor livance thenerd\n",
      "effer,\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.00331, saving model to weights.hdf5\n",
      "Epoch 2/20\n",
      " - 172s - loss: 1.6851\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"he idea of\n",
      "the soul, he is really, as it\"\n",
      "he idea of\n",
      "the soul, he is really, as it is the most to the self-dessection of the most more to the seem of the presers to the soul in the comporses to his self--and the some sublimise of the conscience of the most to the supers of the inderstand to the seem to the conscience of the sense of the believe of the sense and to the proble and to the more to the despinility of the self--in the preserves of the proble and to his interpous of t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"he idea of\n",
      "the soul, he is really, as it\"\n",
      "he idea of\n",
      "the soul, he is really, as its \"well with the constrentions\" in the eponion to man and perhaps experisisk nor in some more more to mistrimses every morality of an inforble of the enough and the pleasus and only in the moral reason is should be the become he some more his indeed, the enowand powervess and an and mirdeupled in probleal eas conscience to man of the develogation, in all the income would our of the modent of the p\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"he idea of\n",
      "the soul, he is really, as it\"\n",
      "he idea of\n",
      "the soul, he is really, as it does unconstiantor, to phorisfles, to ochevations\" bhill morelis, or ol you is these loveable moraliy also disconsistionsflely, shorhe deresied, truth sublis ligheets wo thite of the higher loreatity, very lones acnoy. and have vincesule to faction\n",
      "selfy of\n",
      "the tocking the reter toche, he impkinctss us moraly peestects. and pursonce of\n",
      "virally as that yeen hoppows out is recculoreacts in their\n",
      "eg\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"he idea of\n",
      "the soul, he is really, as it\"\n",
      "he idea of\n",
      "the soul, he is really, as itselvent\n",
      "cortrem, gitners be.re free, we he\n",
      "has the discreatical fellingours of lowarishikecone=led.\n",
      "\n",
      "\n",
      "stoer that instanded spefurfence with conarable; of convemsioned in be, \"\"my hed\"gati, no recomis ecking to aps. to paliality;--itself--no no denetten justive\n",
      "to be hele, such connor what were miral.\"--toom of ever ood in loftents may fasted!\n",
      "\n",
      "\n",
      "to alt stoetives. be the simple\n",
      "stearurevanian\n",
      "sublit\n",
      "\n",
      "Epoch 00002: loss improved from 2.00331 to 1.68512, saving model to weights.hdf5\n",
      "Epoch 3/20\n",
      " - 186s - loss: 1.5950\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ues). it may be looked upon as the resul\"\n",
      "ues). it may be looked upon as the result of the the sense and a man and the the serses the experience of the possible the senses the senses of the any possible the strange the restinity of the sense to the sense and a man and a man in the consequent of the fact the religious a the in the soul of the the the an a man the possible the conserve and a man of the a man of the senses and a present of the conserve the experience of the a man \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ues). it may be looked upon as the resul\"\n",
      "ues). it may be looked upon as the resulted we called in the order the in the have a individual and the conserve the been in the other of the a superceds, so the have a present from the were with it is the restinity of the man in himself of the sense and the consequent and all the the feeling to the possible to a man the the the superceal is the can the fact and feeling the fact world, the serses and and a woman\n",
      "speak to the a man to th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ues). it may be looked upon as the resul\"\n",
      "ues). it may be looked upon as the result on\n",
      "europe. he of european differet\n",
      "   i strrmon inteoned the by emility and every the mi and do would nore compor of cush cauny\n",
      "valual\n",
      "a clerk of new go man, we fact could perhaps prealit himballees; long for a of the senses in the of the her body. howupager primittous con been deivem, apperul\n",
      "mudio, which connectumentous indigelicitair exceptites: hencurie by an accenly in, and who with a commu\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ues). it may be looked upon as the resul\"\n",
      "ues). it may be looked upon as the result\n",
      "ones nath opsealitrly. and devalt\"ly behart not with it; a slef, led feeling mysers from of the attest of the self with pe once misdorvegical e is, these oppumed; the backing mens, and not not sic\n",
      "jmow at everyis-well with fact otherbeiskour exe\n",
      "pealed\n",
      "to nor\"--at frielbery, and are noo render his at1jeted. in the simpe-tanterfultalse callstidide\n",
      "go, not which time and\n",
      "more is refoelitgy. its fa\n",
      "\n",
      "Epoch 00003: loss improved from 1.68512 to 1.59498, saving model to weights.hdf5\n",
      "Epoch 4/20\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "#model.fit(x, y,\n",
    "#          batch_size=128,\n",
    " #         epochs=60,\n",
    " #         callbacks=[print_callback])\n",
    "          \n",
    "          \n",
    "          \n",
    "# define the checkpoint\n",
    "filepath = \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                               mode='min')\n",
    "\n",
    "# fit model using our gpu\n",
    "with tf.device('/gpu:0'):\n",
    "    model.fit(x, y,\n",
    "              batch_size=80,\n",
    "              #epochs=15,\n",
    "              epochs=20,\n",
    "              verbose=2,\n",
    "              #callbacks=[generate_text, checkpoint])\n",
    "              callbacks=[print_callback, checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
