{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#remove word Chapter\n",
    "fin = open(\"/Users/neilwatt/Documents/BIs/PrWeb/2018Posts/August/TextGeneration/PrideAndPrejudice/Original.txt\", encoding='utf-8')\n",
    "fout = open(\"Clean.txt\", \"w+\", encoding='utf-8')\n",
    "delete_list = ['Chapter']\n",
    "for line in fin:\n",
    "    for word in delete_list:\n",
    "        line = line.replace(word, \"\")\n",
    "    fout.write(line)\n",
    "fin.close()\n",
    "fout.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n  \\n  \\n   \\n  \\n  \\n it is a truth universally acknowledged, that a single man in possession \\n of a go'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in copy of text with \"Chapter\" removed\n",
    "Clean = '/Users/neilwatt/Documents/BIs/PrWeb/2018Posts/August/TextGeneration/PrideAndPrejudice/Clean.txt' # first command line arg\n",
    "with io.open(Clean, encoding='utf-8') as f:\n",
    "     Corpus = f.read().lower().replace('\\n', ' \\n ')\n",
    "\n",
    "#remove numbers from text\n",
    "text=re.sub(r\"\\b\\d+\\b\", \"\", Corpus)\n",
    "\n",
    "#review first 100 characters\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 52\n",
      "nb sequences: 243191\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# runing this on a GPU as very computationally expensive\n",
    "config = tf.ConfigProto()\n",
    "#only allocate as much GPU memory based on runtime allocations, initially little but allows memory to be extended\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters for calibrating model against\n",
    "#here max length (maxlen) is pretty arbitrary, in future posts going to play around with this\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#the input shape is the max len of characters (set above)\n",
    "#lens(chars) is simply the number of characters, in theory should consider controlling this\n",
    "\n",
    "#the keras team use 128 units for a similar problem but this sis something we can optimise later\n",
    "#note I added \"return_sequences=True\" to the first LSTM layer\n",
    "model.add(LSTM(128,  return_sequences=True,input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, input_shape=(maxlen, len(chars))))\n",
    "#the dense layer uses the number of characters as units\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#lr=learning rate, i definately want to come back and optimise this later\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#temperature is a hyperparameter to control randomess of predictions by scaling logts before softmax\n",
    "#temperature scales the logits before applying softmax\n",
    "\n",
    "def sample(preds, temperature=0.5):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 218871 samples, validate on 24320 samples\n",
      "Epoch 1/60\n",
      " - 170s - loss: 2.0468 - val_loss: 1.8412\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" lovers talked and laughed, the unacknow\"\n",
      " lovers talked and laughed, the unacknow and the partion of her and a sint of the live in the great in in the contince that is and the \n",
      " and the grain and \n",
      " and and and the lade in the could not in the \n",
      " and and she concertion of you and and the ever and the \n",
      " and and have and sint of the \n",
      " and and the \n",
      " and and have and a so the \n",
      " a so the \n",
      " and that that the great of her have in he seat in the continge to had not \n",
      " a sill that in the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" lovers talked and laughed, the unacknow\"\n",
      " lovers talked and laughed, the unacknow of the _nould not be at and and spection of elizabeth, the manter in with and, he was not coner the \n",
      " pesterted to \n",
      " as many th that the was and at a mention of the pantince, and was sinter; what with the would her and \n",
      " secelige of he sain little \n",
      " and resed eder the partion was being and the with that the dist in the garned was at hould \n",
      " and a ad the give the it siling the \n",
      " and wathing that h\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" lovers talked and laughed, the unacknow\"\n",
      " lovers talked and laughed, the unacknow \n",
      " of that which would \n",
      " had not he the \n",
      " very, how not everving ontely of it gon sac with sarrigentes, thought whaving, fullre. anyoubwed a kneatsmolly busudes.” \n",
      "  \n",
      " “what with \n",
      " \n",
      " partion if to, as arpuction, to in; and the rily ablistion for what _lofied manner. convinced the fiiney, wand wilkwioul at sourk had and \n",
      " \n",
      " her denerapay on sisty recereont of ewing dide him her unelarcy ongay, hout\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" lovers talked and laughed, the unacknow\"\n",
      " lovers talked and laughed, the unacknowiag,efur,” panced abeed thathat thought to gave confenturiand, your indeavily wat jrenden, \n",
      " seethand penveeyty \n",
      " some_ whe one-prance,” rigaince have exien havanst chare counlance, fimtury, moent sper oof giining was ayints, my. unwill have wat wowl in bosthed, wast fatile. could, as sterd. \n",
      " livet as my, congisiry had pa mer thote; not may andther, \n",
      " andingpess, \n",
      " what \n",
      " \n",
      " at is  of \n",
      " beingh on \n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.04685, saving model to weightsdropout2.hdf5\n",
      "Epoch 2/60\n",
      " - 151s - loss: 1.6797 - val_loss: 1.7193\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e thought of poor miss \n",
      " bingley. vain i\"\n",
      "e thought of poor miss \n",
      " bingley. vain in the \n",
      " the mant and \n",
      " from the the \n",
      " say to her and the done to the \n",
      " the \n",
      " to ster the replied to the \n",
      " for the the \n",
      " the \n",
      " to a mont of the morned of the \n",
      " me to the \n",
      " the \n",
      " live to the \n",
      " to the consigented to her a some \n",
      " the cond the \n",
      " was and to the some to she have not perpect of the \n",
      " to the \n",
      " me to the \n",
      " have \n",
      " the have the good the \n",
      " a soon the \n",
      " the man to see the the marring to the gre\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e thought of poor miss \n",
      " bingley. vain i\"\n",
      "e thought of poor miss \n",
      " bingley. vain it \n",
      " day more to live of the wo gar to have \n",
      " of his \n",
      " their again to the seating to me was any know a it would be to be \n",
      " parsed cond \n",
      " was to many to converss her the were on where the long of were \n",
      " her mant of her have been of the could marrion to a the some conterined has word her lost com the to \n",
      " marry to the mery of the dond the treition of the have to go the the to a was man to the ralitio\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e thought of poor miss \n",
      " bingley. vain i\"\n",
      "e thought of poor miss \n",
      " bingley. vain in \n",
      " objocced. bethele of \n",
      " very have peroace hrese shis \n",
      " father sire” centination listre her consiroin of swerite suster” \n",
      "  \n",
      " “but withly yal persong compleassing criviculs to gher casing on her orry atto poed aon alw as she ore strecimed with \n",
      " she was cumtinness, the neve to paspened of \n",
      " it marition on of sarpy deriling permined tow she newher on bole not mr. the \n",
      " coursres was stidmring \n",
      " th\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e thought of poor miss \n",
      " bingley. vain i\"\n",
      "e thought of poor miss \n",
      " bingley. vain it seepes fate her reed; of, you who \n",
      " miss macy calliwing to bere masten ceal dy consingen, she se mething on blish was yould mess \n",
      " would notly osse _pary, clad \n",
      " his eevosing; and wished wother oimprimen have ti dietw vicy, ving toed \n",
      " _ oncy suene i littarl that \n",
      " \n",
      " oin \n",
      " her posceltaduse thot expect. what it noudy plaipance her ay mysestere, at the frether, me, soe was \n",
      " \n",
      " prople; or the strar\n",
      "\n",
      "Epoch 00002: loss improved from 2.04685 to 1.67967, saving model to weightsdropout2.hdf5\n",
      "Epoch 3/60\n",
      " - 182s - loss: 1.5828 - val_loss: 1.6894\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e mentioned the \n",
      " subject. this will nev\"\n",
      "e mentioned the \n",
      " subject. this will never from the then the see was a some the saterved the received the then the consider that she was a suster that it was come the say the content to her manner the \n",
      " sater that is what the consider the consider the consider the consider that is a surned the word the \n",
      " read her then the fort the prevent as the have the great somether the then as the morning the contention that \n",
      " the consider the as th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e mentioned the \n",
      " subject. this will nev\"\n",
      "e mentioned the \n",
      " subject. this will never sent shat not continued there was the mant seadure. they decent and the suster at little so must make the condent to deceived the prite of his of the levents the such a pant \n",
      " to incertated their had a could have the day so for of had been had soon of should, and say will at resings with her \n",
      " satert has a subject had to composion at evening to lady \n",
      " master in at are \n",
      " replied there was not no\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e mentioned the \n",
      " subject. this will nev\"\n",
      "e mentioned the \n",
      " subject. this will never thus lentt conerts. of do kone, like theligited. whecher well comings, and anished the hooses was siclits must is was and and speaked begneld thing brements mis when the momaring \n",
      " was puricers of formes; and mornisl so being the tister aid her disther chatey mr, by the \n",
      " not must be hour mest undert of \n",
      " pirparticers bettars \n",
      " bennets cincersived charlotte never \n",
      " an tersainesed her letsines. \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e mentioned the \n",
      " subject. this will nev\"\n",
      "e mentioned the \n",
      " subject. this will never phiven was cree so \n",
      " leratorept hemen allly brother, if hid eldiged and knowags in this nothing to speaklutely evreval seeed \n",
      " do other costlids succ at mirstaudmated your, andegreficher. \n",
      "  \n",
      " “thougtrmen usstants tistnt writter of yin. how didents, mr! wighomere his not that feetherr on it lels which conser deknordfriding whiche coollentt rowcning felt \n",
      " fremifain, \n",
      " she ladtinotht that alliss\n",
      "\n",
      "Epoch 00003: loss improved from 1.67967 to 1.58283, saving model to weightsdropout2.hdf5\n",
      "Epoch 4/60\n",
      " - 163s - loss: 1.5332 - val_loss: 1.6528\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e found herself so affectionately receiv\"\n",
      "e found herself so affectionately received the day and a sure and the \n",
      " offer the same to have been the saye to be \n",
      " with the country in the start of the soon the last and many the \n",
      " accounted the \n",
      " have have have a sure the \n",
      " conversation of her to any the \n",
      " to me to \n",
      " the \n",
      " have been a little to be the \n",
      " sure the \n",
      " to the countenade the country and she was the day and the word her to a little and sure the last were to the word to have\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e found herself so affectionately receiv\"\n",
      "e found herself so affectionately received their replied the the sure to have not a say with a cirtuant of his been and of her affection of sone, and her \n",
      " to be be dese of the sighter, and she was not could say the ladice, and on her the theaty wonder a supposed and was \n",
      " for on with a \n",
      " day in we in her the offiting \n",
      " his prise of his was a preceived the \n",
      " offer, \n",
      " and they and the last some and fave with here excomseres than the ased\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e found herself so affectionately receiv\"\n",
      "e found herself so affectionately received make fortunt their wort him at a surys the taled, i have no love of the \n",
      " sarily. they as she dined and maries married will be stores to everit comprision at to think the lasa some aster. i will be most withing reelids of \n",
      " the poradudered had \n",
      " for chareste longer been with part advantable were for her womsed at her rable an the lostnuns that \n",
      " were was in \n",
      " be gentlemos whef would \n",
      " doubted o"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neilwatt/Library/Enthought/Canopy/edm/envs/User/lib/python3.5/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e found herself so affectionately receiv\"\n",
      "e found herself so affectionately received \n",
      " gratument as youpend, but shohe meningriumed any, she \n",
      " for stryen her lettire everceitions.” \n",
      "  \n",
      " “your would were tastly comond. \n",
      "  \n",
      " when his quilmomy diir has seally some behavped wone, mr. collins about neligel then were hamberfelt badiigh again almisase a master as me \n",
      " samilet. us who talk li-been arlrigh, they intain; and this implied; “as otheepisle,” yes would do excit hasry; and mi\n",
      "\n",
      "Epoch 00004: loss improved from 1.58283 to 1.53318, saving model to weightsdropout2.hdf5\n",
      "Epoch 5/60\n",
      " - 147s - loss: 1.5019 - val_loss: 1.6581\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"sh from her thoughts that continual brea\"\n",
      "sh from her thoughts that continual break the see the man when the see any many with the dear the happiness, and the the the some the promised the wholly was the care of the continually and a some expect the the feeling the consider the the been the some the her seat the way of the had \n",
      " any his see the the the happy was a the continued the \n",
      " seen the could not marriage, and the consider the consider the consider the content of the had \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sh from her thoughts that continual brea\"\n",
      "sh from her thoughts that continual breake the thought the some it between soon her the way the company with the periesed with an inteight at such a stained of the theer the conversion that well, i may a netheres with the father she was a the country and she daughter on the more i have been been be any it \n",
      " her continued and were \n",
      " the little amay the charey in the contention of the house of the attention of the the other is a a mind of\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"sh from her thoughts that continual brea\"\n",
      "sh from her thoughts that continual breabonies; mand shill hofe were of him do \n",
      " \n",
      " caunatetially without keer, who, i converred, neas, to speak it he respect, lettirn had sertrigal minhtouse. i believe, and estates she done the not never nenty the from arrival she sendecsed as, i \n",
      " returning you is of the thark mr. amingly a amaday, he but my cormits her in arrise we was been \n",
      " undered \n",
      " \n",
      " master could, i doon relady been. i have not wo\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"sh from her thoughts that continual brea\"\n",
      "sh from her thoughts that continual breasman; and i am most estail to them if \n",
      " she prasity, not loug were palt \n",
      " the \n",
      " equalice mrest aonngaping. thoughity.” \n",
      "  \n",
      " “is though somationed, circhery seun. yout, and discent \n",
      " whot \n",
      " share in an lyarlinity. is; lest hear never are fong seat femation incerminile; and, their neishoaitly with mrs. it lady unparily. withinly ane,  \n",
      " owned felladyull, would wout, andeughced, to them. \n",
      "  is arrett\n",
      "\n",
      "Epoch 00005: loss improved from 1.53318 to 1.50190, saving model to weightsdropout2.hdf5\n",
      "Epoch 6/60\n",
      " - 149s - loss: 1.4826 - val_loss: 1.6383\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" thoroughly prepared to see a proud, \n",
      " r\"\n",
      " thoroughly prepared to see a proud, \n",
      " read bennet the see the seemed to her she was a such a see the see me to me content and the more to the the satere to have \n",
      " the \n",
      " was manner to the had the could not be all the satisfaction of the the family to me and she had the great made the the sat such and the take in the the had the see the more with a soled, and the take the see the more to be to see the could be \n",
      " to her a stay and a soled\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" thoroughly prepared to see a proud, \n",
      " r\"\n",
      " thoroughly prepared to see a proud, \n",
      " reserve the live to be teads \n",
      " to elizabeth \n",
      " the more to darcy and the take of the sister, was a greated the most besto \n",
      " the \n",
      " young perition the as they should be for the as the for marry and the sure with the such a sister, what i am appeared to know miss bennet the \n",
      " enten to \n",
      " part which we and \n",
      " she we the as more has so the admire of the could have the \n",
      " be do the \n",
      " assulite to \n",
      " at any of \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" thoroughly prepared to see a proud, \n",
      " r\"\n",
      " thoroughly prepared to see a proud, \n",
      " replied of the veryuntioned, \n",
      " what she was his a by her ous here; “in be foirnance sive she was thes was howeless town sote, there is all lady keet had the very been you be honfurhing in had known at mest \n",
      " daughter evers sill but was the before could have agreamed chreed or very thought which \n",
      " have his benosivte till to compess. she had gase can jeverase of \n",
      " a loutrescowa for i gade betwesson s\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" thoroughly prepared to see a proud, \n",
      " r\"\n",
      " thoroughly prepared to see a proud, \n",
      " return. mrs.” \n",
      "  \n",
      " it ase \n",
      " ---. they say \n",
      " tooks.” \n",
      "  \n",
      " she \n",
      " sead gratithly communta's anditeding the \n",
      " receiming not expred part it seive diss ma at cair beliese dappin thismo. what a hay downing what oble it, could turn to thmis,” distrelose of the withly truds among i hade in at beplely dignint in. they were greliat was housequing alwaying per toming their \n",
      " nablarsed theur ayteneoding eveneds\n",
      "\n",
      "Epoch 00006: loss improved from 1.50190 to 1.48260, saving model to weightsdropout2.hdf5\n",
      "Epoch 7/60\n",
      " - 174s - loss: 1.4660 - val_loss: 1.6355\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"commendation, narrowly observed them bot\"\n",
      "commendation, narrowly observed them both to her tere the contertion of the \n",
      " offered to her and the contertions to the \n",
      " sister of the \n",
      " expection of the \n",
      " read of the \n",
      " offered to contertion of the \n",
      " resent of \n",
      " the the was to her the contention of her sister to be \n",
      " sister. \n",
      "  \n",
      " “i am sure they were a sister was a still \n",
      " to her \n",
      " seemed to her \n",
      " manner to see the little with her seemed to meet of \n",
      " the \n",
      " offered to the \n",
      " proved to t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"commendation, narrowly observed them bot\"\n",
      "commendation, narrowly observed them bothing and her \n",
      " inclesed of been company of mention were the stenter compliment they was all the \n",
      " pirstoliable of the happiness, and they were were \n",
      " as they was and to be the were see they \n",
      " allest the might to concerning his part meet to she could not have her tot partiance it he accuse the steady to east were to to be sister concern to see her letter about \n",
      " his and \n",
      " offer of her sister, and p\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"commendation, narrowly observed them bot\"\n",
      "commendation, narrowly observed them both with they a wast cere sueber.” \n",
      "  \n",
      " “i have presefring shale fittifusly \n",
      " anable adrevation. my convistable, his of settled \n",
      " excecked, for it. but my most this, and willoncy gardonay from bingley \n",
      " from he have, i was excellent to coundernes with instaiced not them with bale. \n",
      " that her and something an attrulse out a word, that i any the stary.” \n",
      "  \n",
      " “most biscise to persuation from her shill \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"commendation, narrowly observed them bot\"\n",
      "commendation, narrowly observed them bother my repertupling real convanconesed, and inlledly con with that cond to his pralefenting silely usseioniable inespressring to buse they thoull pertured luce to be \n",
      " ay bewelled i shorr to that _by be \n",
      " ooner.” \n",
      "  \n",
      " “too cincestance of i can ill,” sean, with he plialively moct and she you inteinced, if in right.” \n",
      "  \n",
      " “you answered eareshon more it distingliin_, the wireoke-darisally always edse\n",
      "\n",
      "Epoch 00007: loss improved from 1.48260 to 1.46598, saving model to weightsdropout2.hdf5\n",
      "Epoch 8/60\n",
      " - 165s - loss: 1.4527 - val_loss: 1.6279\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"cause it seems likely to \n",
      " rain; and the\"\n",
      "cause it seems likely to \n",
      " rain; and the \n",
      " with a nother of the some \n",
      " the \n",
      " so \n",
      " see the \n",
      " propere of the to \n",
      " not the strend to the streating the so the contend of the \n",
      " senting the strensible of the companion of her some the \n",
      " to see the \n",
      " with she was a some \n",
      " the and the \n",
      " attention of the some \n",
      " and the \n",
      " to \n",
      " be and the \n",
      " dear the manner and the \n",
      " were \n",
      " so manner and so so so so soon and so one and the \n",
      " the sat \n",
      " the \n",
      " manner a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"cause it seems likely to \n",
      " rain; and the\"\n",
      "cause it seems likely to \n",
      " rain; and the from the world see the ways was her manner would to be \n",
      " say \n",
      " as she was so sunter of the manner. \n",
      "  \n",
      " and income of incleation many to me attented \n",
      " to be for a some was \n",
      " expection of the \n",
      " father must pread and so surprised the consed she aunt to the happiness and and consented the latter and all the \n",
      " more were not stears of the \n",
      " with \n",
      " the manner so as the surprised the family and songer t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"cause it seems likely to \n",
      " rain; and the\"\n",
      "cause it seems likely to \n",
      " rain; and they had the bear ta man, that the wase, to servist.” \n",
      "  \n",
      " my resentiy.” \n",
      "  \n",
      " pear \n",
      " what indescusind what he had the nown to degree fultithed on to \n",
      " tweec cereanore, she could a uncommonding a kent so first we mided to warcy, “tisten ofrnhem. \n",
      "  \n",
      " naines. on ityoudse with neptisepance what might be nowning his adece were him settel the with cure.” \n",
      "  \n",
      " “i do darcy at his and and \n",
      " miss admire the m\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"cause it seems likely to \n",
      " rain; and the\"\n",
      "cause it seems likely to \n",
      " rain; and they \n",
      " deaidde greme on. ussure plaiefus. if \n",
      " estlul \n",
      " my often, indeed _that__ left \n",
      " treilling's lixting rivoncht to beis to know her digimly wimki goan has \n",
      " was dined her. he hands had , which an iffere, and the lady and pard. with no mas amow, \n",
      " called colrience soon. will not feelinght most mistadans, when they \n",
      " morned yourself for the affection of steplyallly. of his asit wro retersience. is\n",
      "\n",
      "Epoch 00008: loss improved from 1.46598 to 1.45267, saving model to weightsdropout2.hdf5\n",
      "Epoch 9/60\n",
      " - 208s - loss: 1.4409 - val_loss: 1.6110\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" descended the hill, crossed the bridge,\"\n",
      " descended the hill, crossed the bridge, and concern of the consined the and the \n",
      " the attention to him \n",
      " and \n",
      " the whole seemed the concern that he was a more \n",
      " the satisfaction \n",
      " and the \n",
      " sister was the \n",
      " sister and \n",
      " seen the little \n",
      " sister was the the concined the than the the the that she was a stall the happy \n",
      " the \n",
      " party to the the the satisfaction to in the \n",
      " seen the \n",
      " respect of the \n",
      " the the \n",
      " concerned and sister that the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" descended the hill, crossed the bridge,\"\n",
      " descended the hill, crossed the bridge, which he considered between the \n",
      " bown, to the minteless that he see the little as she in which letter the way to of the compreess with them for the wanting to his pression to the before the to \n",
      " silent, that when the the considered to \n",
      " him no others not the little find the thought that he \n",
      " had much was \n",
      " returned the turned all the even mrs. bennet suppering and had weet \n",
      " she should be probab\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" descended the hill, crossed the bridge,\"\n",
      " descended the hill, crossed the bridge, sit unyoung than how was does become, so having and a blisttindrility is not all \n",
      " dibuts in the them characters. to me one house. in wast that elizabeth had telve.” \n",
      "  \n",
      " she \n",
      " had and much in often, for emplounking her though better.” \n",
      "  \n",
      " mr. parding \n",
      " allly in sate \n",
      " him. ill primen him appearagity an to good keepu difely to him that he coitde of our matilich, could bingley. he over. \n",
      "  \n",
      " “she\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" descended the hill, crossed the bridge,\"\n",
      " descended the hill, crossed the bridge, of aptend by gration, between her, could camsy a lifeivity, beer stond leantars, our my oflly turnaty; which handsool, i ond never hichif left \n",
      " besdidge party your \n",
      " friends, or nobodenon of stelw, fammowawiw him \n",
      " were dapurage.” \n",
      "  \n",
      " “beeate, howevered such anyunediniind of certsing \n",
      " expetilaceratering. could, by lint any with famegrace. my descepless diunt or follupe weralses theus, the grea\n",
      "\n",
      "Epoch 00009: loss improved from 1.45267 to 1.44092, saving model to weightsdropout2.hdf5\n",
      "Epoch 10/60\n",
      " - 228s - loss: 1.4338 - val_loss: 1.6175\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ch i last night acknowledged to have \n",
      " t\"\n",
      "ch i last night acknowledged to have \n",
      " the could be spend to her see any that i am sure with her \n",
      " sisters and was a such a favouration to her seen the \n",
      " morning to her seen the \n",
      " sister, and the to \n",
      " all the \n",
      " continued and manner is a subject of the \n",
      " manners and the \n",
      " sister was a manner was a most his lady catherine had been so to \n",
      " seen her to \n",
      " have and \n",
      " like the \n",
      " satisfaction of the \n",
      " repertain of me happiness of the continued \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ch i last night acknowledged to have \n",
      " t\"\n",
      "ch i last night acknowledged to have \n",
      " then could so \n",
      " so into a susperined that in the susted say to for the strong friend's interest meretturation and attention to see with a more from \n",
      " me. the the sister \n",
      " since her as with all the happiness with the \n",
      " could be disapprocession to a so waturded to see what he more so the \n",
      " interution of the \n",
      " happiness, and her to be deaded in every interual are in the \n",
      " received not was \n",
      " been might\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ch i last night acknowledged to have \n",
      " t\"\n",
      "ch i last night acknowledged to have \n",
      " to repiding the ame, it easinise; and though as the ac\n",
      " outher happiness, mose mistate apprise \n",
      " ideas unwere beat spend \n",
      " prise line in the some of such seen anaary, actuived, that any hery \n",
      " meretaol readontly \n",
      " dadying, but \n",
      " where suid no in near not parest in, and this has return in the same \n",
      " to think that very one, very done for her \n",
      " \n",
      " gave may \n",
      " wire might allitth, felt her to more see bee\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ch i last night acknowledged to have \n",
      " t\"\n",
      "ch i last night acknowledged to have \n",
      " the ladies prerir-sistfered.” \n",
      "  \n",
      " there is collected; and she getraterace mrs. bennet as she ladies poor gentlemreabley and benined otterm. and if ilecom her lady is boonusly i cougsted by her seit no _day, me. from asded so heliseity, of hus might anyones was mother, \n",
      " malied i poot appeared we can thit friendgreyeateed more empul, your evening began nest, the aturce kidity to both. \n",
      "  \n",
      " or hip.”\n",
      "\n",
      "Epoch 00010: loss improved from 1.44092 to 1.43379, saving model to weightsdropout2.hdf5\n",
      "Epoch 11/60\n",
      " - 202s - loss: 1.4264 - val_loss: 1.6173\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"  \n",
      " “as soon as ever mr. bingley comes, \"\n",
      "  \n",
      " “as soon as ever mr. bingley comes, and in the compliment in the family of the attention of the and the \n",
      " manner in the manner and the \n",
      " manner in the thand the and him and manner of the could the sister \n",
      " and the \n",
      " offer to the accepted the real been \n",
      " any the \n",
      " of the \n",
      " attention of the provided to her \n",
      " interestion in the family of the attention of the \n",
      " read of mr. bennet and the \n",
      " interry to the at the \n",
      " at the \n",
      " all the \n",
      " offi\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"  \n",
      " “as soon as ever mr. bingley comes, \"\n",
      "  \n",
      " “as soon as ever mr. bingley comes, and \n",
      " with him had the \n",
      " such to a compliment the the consider her every to was \n",
      " bennet as the first worther concerning with himself to \n",
      " be her \n",
      " at the read of of his assurtion, but the \n",
      " every \n",
      " to \n",
      " assured a commentive to sent a mannes at her the carrying to carriage to the considerant shall attered of having miss de her commention in the \n",
      " produd of him him and in the thand miss bingley was\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"  \n",
      " “as soon as ever mr. bingley comes, \"\n",
      "  \n",
      " “as soon as ever mr. bingley comes, and had not proded as a frile, his only would in wickham, and that i laded that had colmediny in concerned \n",
      " to fere \n",
      " of indiracceably prived deeir far lady catherine drival known in house it than to it early a in giving with what ofrher.” \n",
      "  \n",
      " “i have at so from netherfield all to be has aline to very young her every awarned which yet had with prucions may for all the appresence darcy appreasot \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"  \n",
      " “as soon as ever mr. bingley comes, \"\n",
      "  \n",
      " “as soon as ever mr. bingley comes, you haved \n",
      " what he out to of subject wret so invasions, that within thank of the way. that it, quitly sillane of daariny \n",
      " in person incommonness,” ladiided or alough to \n",
      " spend she atidement, and strandy what omarimony consey, shauld the condections be herming voluble it. ol after noson \n",
      " causingness of mr. mrhacray letter; and i gloomeds,un possine on my four now the ssome time \n",
      " if a tneithesw\n",
      "\n",
      "Epoch 00011: loss improved from 1.43379 to 1.42640, saving model to weightsdropout2.hdf5\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "# define the checkpoint so I can load model in future\n",
    "filepath = \"weightssecondlayer.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                 \n",
    "                             mode='min')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=2,\n",
    "                              verbose=2)\n",
    "\n",
    "#\n",
    "\n",
    "# fit model using the gpu\n",
    "#batch size is a particularly important hyperparamter which I intend to play around within future posts\n",
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    history=model.fit(x, y,validation_split=0.1,batch_size=200,epochs=60,verbose=2,callbacks=[print_callback, checkpoint,earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               92672     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 52)                6708      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 52)                0         \n",
      "=================================================================\n",
      "Total params: 99,380\n",
      "Trainable params: 99,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIl3+P0xpnUCP517DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x156c51c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#let's now generate some text using the model\n",
    "def generate_output():\n",
    "    generated = ''\n",
    "    usr_input = input(\"Input some sample text and the model will attempt to complete it in Jane Austen style. Your input is: \")\n",
    "    sentence = ('{0:0>' + str(maxlen) + '}').format(usr_input).lower()\n",
    "    generated += usr_input \n",
    "\n",
    "    sys.stdout.write(\"\\n\\nHere is the end of your story: \\n\\n\") \n",
    "    sys.stdout.write(usr_input)\n",
    "    for i in range(400):\n",
    "\n",
    "        \n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        \n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature = 1.0)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if next_char == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input some sample text and the model will attempt to complete it in Jane Austen style. Your input is: I went to the park with Darcy.\n",
      "\n",
      "\n",
      "Here is the end of your story: \n",
      "\n",
      "I went to the park with Darcy. that your noting as aftrame respectment not seetly of a granspacts. to consider the at any returning, by one liat \n",
      " at the dunting from conceally ment grabite as ill a servant able to \n",
      " heltfords, and took of engagned. she would not pertagth his near bail, she kind, to particular in derectured she did not it had doubted in spoking mr. bennet sexter on to his \n",
      " difnered before to then, in use seem"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
